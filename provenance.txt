A record of the parameters set while training the different availble models, and 


Word2Vec Models:

v1
model = Word2Vec(allTexts, workers = 54, size = 300, iter = 10, window = 10, min_count = 10, sample = 1e-5)
#Observation: much better than v2.

v2
model = Word2Vec(allTexts, workers = 18, size = 300, iter = 25, window = 8, min_count = 15, sample = 1e-5, negative = 20)

Currently Running
Shuffled the list before starting.
model = Word2Vec(allTexts, workers = 40, size = 300, iter = 16, window = 10, min_count = 8, sample = 1e-5)
#Observation: Seems to be running *QUITE* a bit faster than v1? Hardware-related?
* Maybe not as fast as originally assumed.

---

Rejects:
tests = 
dharmasankat - nayak
waasana -kaamwaasana
udar - bajarmukhi

Negatives:

Grahan - shapath - swamitwa